# -*- coding: utf-8 -*-
"""4 augmente taille d'image  rakazit fih.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vt5vYrsmvZZeCrUSVzdDXoWhTzb5foZL
"""





#inxtallation de bibliotheque
#biblioth√®que principale de deep learning.

import tensorflow as tf
from keras.src.applications.convnext import preprocess_input

#Optimise automatiquement le chargement des donn√©es pour √™tre rapide.
AUTOTUNE = tf.data.AUTOTUNE













import tensorflow_datasets as tfds


#charger dataset
def preprocess(example):
    image = example['image']
    image = tf.image.resize(image, [128, 128])  # Redimensionne √† 64x64
    image = tf.cast(image, tf.float32) / 127.5 - 1.0  # Normalise les pixels entre [-1, 1]
    return image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from PIL import Image, UnidentifiedImageError

datagen = ImageDataGenerator(rescale=1./127.5 - 1.0)

train_data = datagen.flow_from_directory(
    "C:/Users/hp/Datasets/PetImages",
    target_size=(96, 96),
    batch_size=48,
    class_mode=None,
    shuffle=True
)

# Chargement des images avec gestion des erreurs
for i in range(len(train_data)):
    try:
        images = train_data[i]
        print(f"‚úÖ Batch {i} charg√© avec succ√®s - Shape: {images.shape}")
        # Vous pouvez ici faire appel √† votre mod√®le encoder, etc.
    except UnidentifiedImageError:
        print(f"‚ö†Ô∏è Image corrompue d√©tect√©e dans le batch {i}, elle sera ignor√©e.")
    except Exception as e:
        print(f"üö´ Erreur inattendue dans le batch {i} : {e}")

print("jjjjjjjjjjjjjjjj")
# Chargement du dataset COCO
import os
from PIL import Image
import os
import os
from PIL import Image


BATCH_SIZE = 48
WATERMARK_LENGTH = 30
#G√©n√®re pour chaque image un tatouage binaire al√©atoire (0 ou 1), converti en float.
# Lors de l'entra√Ænement
for images in train_data:
  #tensor 48,64,64,3
    batch_size = tf.shape(images)[0]
    #print("batch size")
    #print (batch_size)
    # G√©n√©rer un watermark de taille [batch_size, WATERMARK_LENGTH]
    #maxval et minval valeurs possibles = {0, 1}.
    watermark = tf.random.uniform([batch_size, WATERMARK_LENGTH], minval=0, maxval=2, dtype=tf.int32)
    #convertir en float
    watermark = tf.cast(watermark, tf.float32)
print("jddddd")
import tensorflow as tf
from tensorflow.keras import layers

# G√©n√©rateur = Encoder (int√®gre watermark dans image)
class Encoder(tf.keras.Model):
    def __init__(self, image_channels=3, watermark_length=30):
        super().__init__()
        self.watermark_length = watermark_length

        self.conv_blocks = tf.keras.Sequential([
            layers.Conv2D(96, 3, padding='same'), layers.BatchNormalization(), layers.ReLU(),
            layers.Conv2D(96, 3, padding='same'), layers.BatchNormalization(), layers.ReLU(),
            layers.Conv2D(96, 3, padding='same'), layers.BatchNormalization(), layers.ReLU(),
            layers.Conv2D(96, 3, padding='same'), layers.BatchNormalization(), layers.ReLU(),
        ])
#fusion creation de tenseur
        self.merge = layers.Conv2D(96, 3, padding='same', activation='relu')
        #applique 3 filtre image channels 64+3+30 ------> 3
        self.final_conv = layers.Conv2D(image_channels, 1)
#pour appeler encoder
    def call(self, image, watermark):
        batch_size, h, w, _ = tf.unstack(tf.shape(image))
        #resdimension watermarking
        wm = tf.reshape(watermark, (batch_size, 1, 1, self.watermark_length))
        #repeter watermarking achaque pixel d'image
        wm = tf.tile(wm, [1, h, w, 1])
        features = self.conv_blocks(image)
        x = tf.concat([features, image, wm], axis=-1)
        x = self.merge(x)
        return self.final_conv(x)

class Decoder(tf.keras.Model):
    def __init__(self, watermark_length=30):
        super().__init__()
        self.model = tf.keras.Sequential([
            layers.Conv2D(64, 3, padding='same', activation='relu'),
            layers.BatchNormalization(),
            layers.MaxPooling2D(),  # (128 ‚Üí 64)

            layers.Conv2D(64, 3, padding='same', activation='relu'),
            layers.BatchNormalization(),
            layers.MaxPooling2D(),  # (64 ‚Üí 32)

            layers.Conv2D(128, 3, padding='same', activation='relu'),
            layers.BatchNormalization(),
            layers.MaxPooling2D(),  # (32 ‚Üí 16)

            layers.Conv2D(256, 3, padding='same', activation='relu'),
            layers.BatchNormalization(),
            layers.MaxPooling2D(),  # (16 ‚Üí 8)

            layers.GlobalAveragePooling2D(),  # (8x8x256 ‚Üí 256)

            layers.Dense(512, activation='relu'),
            layers.Dropout(0.3),
            layers.Dense(watermark_length, activation='sigmoid')
        ])

    def call(self, x):
        return self.model(x)

class Discriminator(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.model = tf.keras.Sequential([
            layers.Conv2D(32, 4, strides=2, padding='same'),  # 64x64 ‚Üí 32x32
            layers.LeakyReLU(0.2),

            layers.Conv2D(64, 4, strides=2, padding='same'),  # 32x32 ‚Üí 16x16
            layers.LeakyReLU(0.2),
            layers.Dropout(0.3),  # remplace BatchNorm

            layers.Conv2D(128, 4, strides=2, padding='same'),  # 16x16 ‚Üí 8x8
            layers.LeakyReLU(0.2),
            layers.Dropout(0.3),

            layers.GlobalAveragePooling2D(),
            layers.Dense(1)  # output logit
        ])

    def call(self, x):
        return self.model(x)

encoder = Encoder(image_channels=3, watermark_length=30)
decoder = Decoder(watermark_length=30)
discriminator = Discriminator()


#G√©n√®re un batch de 4 images al√©atoires

sample_img = tf.random.uniform((4, 96, 96, 3))
#G√©n√®re un batch de 4 watermarks binaire
sample_wm = tf.random.uniform((4, 30), minval=0, maxval=2, dtype=tf.int32)

encoded = encoder(sample_img, tf.cast(sample_wm, tf.float32))
decoded = decoder(encoded)
disc_score = discriminator(encoded)
print("encoded image shape:", encoded.shape)
print("decoded watermark shape:", decoded.shape)
print("discriminator score shape:", disc_score.shape)

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
nbre_vraie=[]
def generate_images_from_outputs(image, watermark, watermarked, decoded, epoch=None):
    # === Affichage des valeurs num√©riques ===
    print("\n--- Affichage des vecteurs ---")
    print("Watermark original (0/1)     :", watermark.numpy())
    print("Watermark d√©cod√© (0.0‚Äì1.0)   :", decoded.numpy())


    print("Watermark d√©cod√© (seuill√©)   :", tf.cast(decoded > 0.5, tf.float32).numpy())
    print("Image tatou√©e (pixel [32,32]):", watermarked[0, 32, 32, :].numpy())
    s=tf.cast(decoded > 0.5, tf.float32).numpy()
    correct_bits = tf.cast(tf.equal(watermark, s), tf.float32)
    nombre_bits_corrects = tf.reduce_sum(correct_bits).numpy()
    print(f"Nombre de bits corrects : {nombre_bits_corrects}")
    nbre_vraie.append(nombre_bits_corrects)
    plt.figure(figsize=(10, 10))
    plt.plot(nbre_vraie, label='Loss decoded', color='blue')
    plt.legend(); plt.title("Courbes de pertes ")
    plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.grid(True)
    plt.show()



    # === Affichage visuel ===
    plt.figure(figsize=(10, 10))

    # 1. Image originale
    plt.subplot(1, 4, 1)
    plt.imshow((tf.squeeze(image).numpy() + 1) / 2)
    plt.title("Image originale")
    plt.axis("off")

    # 2. Watermark ins√©r√©
    plt.subplot(1, 4, 2)
    wm_np = tf.squeeze(watermark).numpy()
    plt.imshow(wm_np[np.newaxis, :], cmap='gray', aspect='auto', vmin=0, vmax=1, interpolation='nearest')

    plt.title("Watermark ins√©r√©")
    plt.axis("off")

    # 3. Image tatou√©e
    plt.subplot(1, 4, 3)
    plt.imshow((tf.squeeze(watermarked).numpy() + 1) / 2)
    plt.title("Image tatou√©e")
    plt.axis("off")

    # 4. Watermark d√©cod√©
    plt.subplot(1, 4, 4)
    decoded_np = tf.squeeze(decoded).numpy()
    plt.imshow(decoded_np[np.newaxis, :], cmap='gray', aspect='auto', vmin=0, vmax=1, interpolation='nearest')

    plt.title("Watermark d√©cod√©")
    plt.axis("off")

    if epoch is not None:
        plt.suptitle(f"Affichage - √âpoque {epoch}", fontsize=14)

    plt.tight_layout()
    plt.show()

watermark_len = 30
image_channels = 3


optimizer_g = tf.keras.optimizers.Adam(learning_rate=1e-4)
optimizer_d = tf.keras.optimizers.Adam(learning_rate=1e-4)
optimizer_dec = tf.keras.optimizers.Adam(learning_rate=5e-4)


import time, pickle

def sauvegarde_periodique(variable, chemin, intervalle_minutes=10, duree_jours=2):
    duree_secondes = duree_jours * 24 * 60 * 60  # conversion jours ‚Üí secondes
    debut = time.time()

    while time.time() - debut < duree_secondes:
        with open(chemin, 'wb') as f:
            pickle.dump(variable, f)
        print(f"‚úÖ √âtat sauvegard√© √† {time.strftime('%Y-%m-%d %H:%M:%S')}")
        time.sleep(intervalle_minutes * 60)

    print("‚èπÔ∏è Sauvegarde termin√©e apr√®s 2 jours.")

# Exemple d'utilisation :
# sauvegarde_periodique(ma_variable, '/content/drive/MyDrive/state.pkl', intervalle_minutes=10, duree_jours=2)





def perceptual_loss(y_true, y_pred):
    # Remettre les pixels √† l‚Äô√©chelle 0-255 pour VGG16
    y_true = tf.clip_by_value(y_true * 255.0, 0.0, 255.0)
    y_pred = tf.clip_by_value(y_pred * 255.0, 0.0, 255.0)

    # Appliquer le pr√©-traitement sp√©cifique VGG
    y_true = preprocess_input(y_true)
    y_pred = preprocess_input(y_pred)

    # Extraire les features interm√©diaires
    true_features = vgg_model(y_true)
    pred_features = (vgg_.model(y_pred))

    # Calculer la perte de type MSE sur les features
    return tf.reduce_mean(tf.square(true_features - pred_features))












import os, glob, pickle
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.losses import BinaryCrossentropy

# === R√©pertoires de sauvegarde




loss_g_list, loss_d_list, accuracy_d_list, bit_accuracy_list, loss_decoded = [], [], [], [], []


# === Entra√Ænement principal
for epoch in range(start_epoch, 400):
    loss_g_epoch, loss_d_epoch, acc_d_epoch, bit_acc_epoch, loss_decoded_epoch = [], [], [], [], []

    for images in train_data:
        batch_size = tf.shape(images)[0]
        watermark = tf.cast(tf.random.uniform([batch_size, WATERMARK_LENGTH], minval=0, maxval=2, dtype=tf.int32), tf.float32)

        with tf.GradientTape(persistent=True) as tape:
            watermarked = encoder(images, watermark)
            decoded = decoder(watermarked)

            loss_decode = bce(watermark, decoded)
            loss_img = tf.reduce_mean(tf.square(images - watermarked))
            loss_percep = perceptual_loss(images, watermarked)
            loss_gan = bce(tf.ones_like(discriminator(watermarked)), discriminator(watermarked))

            total_loss_g = 500 * loss_decode + 100 * loss_img + 5 * loss_gan

            real_pred = discriminator(images)
            fake_pred = discriminator(tf.stop_gradient(watermarked))

            loss_d_real = bce(tf.ones_like(real_pred), real_pred)
            loss_d_fake = bce(tf.zeros_like(fake_pred), fake_pred)
            loss_d = loss_d_real + loss_d_fake

        # Appliquer les gradients
        grads_g = tape.gradient(total_loss_g, encoder.trainable_variables + decoder.trainable_variables)
        optimizer_g.apply_gradients(zip(grads_g, encoder.trainable_variables + decoder.trainable_variables))

        grads_d = tape.gradient(loss_d, discriminator.trainable_variables)
        optimizer_d.apply_gradients(zip(grads_d, discriminator.trainable_variables))

        with tf.GradientTape() as tape_dec:
            decoded_train = decoder(watermarked)
            loss_decode_dec = bce(watermark, decoded_train)
        grads_dec = tape_dec.gradient(loss_decode_dec, decoder.trainable_variables)
        optimizer_dec.apply_gradients(zip(grads_dec, decoder.trainable_variables))

        # √âvaluation
        acc_real = tf.reduce_mean(tf.cast(real_pred > 0.5, tf.float32))
        acc_fake = tf.reduce_mean(tf.cast(fake_pred < 0.5, tf.float32))
        acc_d = 0.5 * (acc_real + acc_fake)

        predicted_bits = tf.cast(decoded > 0.5, tf.float32)
        bit_accuracy = tf.reduce_mean(tf.cast(predicted_bits == watermark, tf.float32))

        # Stocker m√©triques
        loss_g_epoch.append(total_loss_g.numpy())
        loss_d_epoch.append(loss_d.numpy())
        acc_d_epoch.append(acc_d.numpy())
        bit_acc_epoch.append(bit_accuracy.numpy())
        loss_decoded_epoch.append(loss_decode.numpy())

    # Moyennes par √©poque
    loss_g_list.append(np.mean(loss_g_epoch))
    loss_d_list.append(np.mean(loss_d_epoch))
    accuracy_d_list.append(np.mean(acc_d_epoch))
    bit_accuracy_list.append(np.mean(bit_acc_epoch))
    loss_decoded.append(np.mean(loss_decoded_epoch))

    print(f"‚úÖ Epoch {epoch+1}/400")
    print(f"   Discriminator real/fake : {tf.reduce_mean(real_pred):.4f} / {tf.reduce_mean(fake_pred):.4f}")
    print(f"   G loss : {loss_g_list[-1]:.4f} | D loss : {loss_d_list[-1]:.4f}")
    print(f"   Bit accuracy : {bit_accuracy_list[-1]:.4f} | Image loss : {loss_img.numpy():.4f}")


    results = {
        'loss_g': loss_g_list,
        'loss_d': loss_d_list,
        'accuracy_d': accuracy_d_list,
        'bit_accuracy': bit_accuracy_list,
        'loss_decoded': loss_decoded
    }

    # === Affichage exemples
    sample_image = images[0:1]
    sample_wm = watermark[0:1]
    sample_wm_img = watermarked[0:1]
    sample_decoded = decoded[0:1]

    generate_images_from_outputs(sample_image, sample_wm, sample_wm_img, sample_decoded, epoch=epoch+1)



    # Par exemple pour afficher le premier √©l√©ment du batch
    sample_image = images[0:1]
    sample_wm = watermark[0:1]
    sample_wm_img = watermarked[0:1]
    sample_decoded = decoded[0:1]

    generate_images_from_outputs(sample_image, sample_wm, sample_wm_img, sample_decoded, epoch=epoch+1)
    # G√©n√©rer et afficher

    # === Trac√©s interm√©diaires ===
    plt.figure(figsize=(12, 8))
    plt.plot(loss_g_list, label='Loss G√©n√©rateur', color='blue')
    plt.legend(); plt.title("Courbes de pertes ")
    plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.grid(True)
    plt.show()


    plt.figure(figsize=(12, 8))
    plt.plot(loss_d_list, label='Loss Discriminateur', color='red')
    plt.legend(); plt.title("Courbes de pertes ")
    plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.grid(True)
    plt.show()

    plt.figure(figsize=(12, 4))
    plt.plot(accuracy_d_list, label="Pr√©cision Discriminateur", color='green')
    plt.title("Pr√©cision du Discriminateur"); plt.ylabel("Accuracy"); plt.xlabel("Epoch"); plt.grid(True); plt.legend()
    plt.show()

    # === Sauvegarde des poids
    encoder.save_weights(f'encoder_epoch_{epoch+1}.weights.h5')
    decoder.save_weights(f'decoder_epoch_{epoch+1}.weights.h5')
    print(f"Model saved at epoch {epoch+1}")



