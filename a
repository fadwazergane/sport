# -*- coding: utf-8 -*-
"""5augmente taille d'image  rakazit fih.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1es5_Jze0MKrBU4LMnDNI6MIvcIaJ-dZc
"""

!pip3 install notebook



#inxtallation de bibliotheque
!pip install git+https://github.com/tensorflow/examples.git
#bibliothèque principale de deep learning.
import tensorflow as tf # pour entrainer modek
#facilite le chargement de jeux de données comme COCO.

import tensorflow_datasets as tfds #chager le dataset automatiqument
#mportation d’un modèle utile pour la vision par ordinateur.
from tensorflow_examples.models.pix2pix import pix2pix

import os
import time

import matplotlib.pyplot as plt #afficher les images
from IPython.display import clear_output#nettoie l'affichage dans Colab entre les époques.
#Optimise automatiquement le chargement des données pour être rapide.
AUTOTUNE = tf.data.AUTOTUNE















#charger dataset
def preprocess(example):
    image = example['image']
    image = tf.image.resize(image, [96, 96])  # Redimensionne à 64x64
    image = tf.cast(image, tf.float32) / 127.5 - 1.0  # Normalise les pixels entre [-1, 1]
    return image

# Chargement du dataset COCO
dataset = tfds.load("cats_vs_dogs", split="train[:50%]", shuffle_files=True)
#regroupe en batchs de 48 images
train_data = dataset.map(preprocess).take(1000).batch(48).prefetch(tf.data.AUTOTUNE)

BATCH_SIZE = 48
WATERMARK_LENGTH = 30
#Génère pour chaque image un tatouage binaire aléatoire (0 ou 1), converti en float.
# Lors de l'entraînement
for images in train_data:
  #tensor 48,64,64,3
    batch_size = tf.shape(images)[0]
    #print("batch size")
    #print (batch_size)
    # Générer un watermark de taille [batch_size, WATERMARK_LENGTH]
    #maxval et minval valeurs possibles = {0, 1}.
    watermark = tf.random.uniform([batch_size, WATERMARK_LENGTH], minval=0, maxval=2, dtype=tf.int32)
    #convertir en float
    watermark = tf.cast(watermark, tf.float32)

import tensorflow as tf
from tensorflow.keras import layers

# Générateur = Encoder (intègre watermark dans image)
class Encoder(tf.keras.Model):
    def __init__(self, image_channels=3, watermark_length=30):
        super().__init__()
        self.watermark_length = watermark_length

        self.conv_blocks = tf.keras.Sequential([
            layers.Conv2D(96, 3, padding='same'), layers.BatchNormalization(), layers.ReLU(),
            layers.Conv2D(96, 3, padding='same'), layers.BatchNormalization(), layers.ReLU(),
            layers.Conv2D(96, 3, padding='same'), layers.BatchNormalization(), layers.ReLU(),
            layers.Conv2D(96, 3, padding='same'), layers.BatchNormalization(), layers.ReLU(),
        ])
#fusion creation de tenseur
        self.merge = layers.Conv2D(96, 3, padding='same', activation='relu')
        #applique 3 filtre image channels 64+3+30 ------> 3
        self.final_conv = layers.Conv2D(image_channels, 1)
#pour appeler encoder
    def call(self, image, watermark):
        batch_size, h, w, _ = tf.unstack(tf.shape(image))
        #resdimension watermarking
        wm = tf.reshape(watermark, (batch_size, 1, 1, self.watermark_length))
        #repeter watermarking achaque pixel d'image
        wm = tf.tile(wm, [1, h, w, 1])
        features = self.conv_blocks(image)
        x = tf.concat([features, image, wm], axis=-1)
        x = self.merge(x)
        return self.final_conv(x)

class Decoder(tf.keras.Model):
    def __init__(self, watermark_length=30):
        super().__init__()
        self.model = tf.keras.Sequential([
            layers.Conv2D(64, 3, padding='same', activation='relu'),
            layers.BatchNormalization(),
            layers.MaxPooling2D(),  # (128 → 64)

            layers.Conv2D(64, 3, padding='same', activation='relu'),
            layers.BatchNormalization(),
            layers.MaxPooling2D(),  # (64 → 32)

            layers.Conv2D(128, 3, padding='same', activation='relu'),
            layers.BatchNormalization(),
            layers.MaxPooling2D(),  # (32 → 16)

            layers.Conv2D(256, 3, padding='same', activation='relu'),
            layers.BatchNormalization(),
            layers.MaxPooling2D(),  # (16 → 8)

            layers.GlobalAveragePooling2D(),  # (8x8x256 → 256)

            layers.Dense(512, activation='relu'),
            layers.Dropout(0.3),
            layers.Dense(watermark_length, activation='sigmoid')
        ])

    def call(self, x):
        return self.model(x)

class Discriminator(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.model = tf.keras.Sequential([
            layers.Conv2D(32, 4, strides=2, padding='same'),  # 64x64 → 32x32
            layers.LeakyReLU(0.2),

            layers.Conv2D(64, 4, strides=2, padding='same'),  # 32x32 → 16x16
            layers.LeakyReLU(0.2),
            layers.Dropout(0.3),  # remplace BatchNorm

            layers.Conv2D(128, 4, strides=2, padding='same'),  # 16x16 → 8x8
            layers.LeakyReLU(0.2),
            layers.Dropout(0.3),

            layers.GlobalAveragePooling2D(),
            layers.Dense(1)  # output logit
        ])

    def call(self, x):
        return self.model(x)

encoder = Encoder(image_channels=3, watermark_length=30)
decoder = Decoder(watermark_length=30)
discriminator = Discriminator()


#Génère un batch de 4 images aléatoires

sample_img = tf.random.uniform((4, 96, 96, 3))
#Génère un batch de 4 watermarks binaire
sample_wm = tf.random.uniform((4, 30), minval=0, maxval=2, dtype=tf.int32)

encoded = encoder(sample_img, tf.cast(sample_wm, tf.float32))
decoded = decoder(encoded)
disc_score = discriminator(encoded)
print("encoded image shape:", encoded.shape)
print("decoded watermark shape:", decoded.shape)
print("discriminator score shape:", disc_score.shape)

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
nbre_vraie=[]
def generate_images_from_outputs(image, watermark, watermarked, decoded, epoch=None):
    # === Affichage des valeurs numériques ===
    print("\n--- Affichage des vecteurs ---")
    print("Watermark original (0/1)     :", watermark.numpy())
    print("Watermark décodé (0.0–1.0)   :", decoded.numpy())


    print("Watermark décodé (seuillé)   :", tf.cast(decoded > 0.5, tf.float32).numpy())
    print("Image tatouée (pixel [32,32]):", watermarked[0, 32, 32, :].numpy())
    s=tf.cast(decoded > 0.5, tf.float32).numpy()
    correct_bits = tf.cast(tf.equal(watermark, s), tf.float32)
    nombre_bits_corrects = tf.reduce_sum(correct_bits).numpy()
    print(f"Nombre de bits corrects : {nombre_bits_corrects}")
    nbre_vraie.append(nombre_bits_corrects)
    plt.figure(figsize=(10, 10))
    plt.plot(nbre_vraie, label='Loss decoded', color='blue')
    plt.legend(); plt.title("Courbes de pertes ")
    plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.grid(True)
    plt.show()



    # === Affichage visuel ===
    plt.figure(figsize=(10, 10))

    # 1. Image originale
    plt.subplot(1, 4, 1)
    plt.imshow((tf.squeeze(image).numpy() + 1) / 2)
    plt.title("Image originale")
    plt.axis("off")

    # 2. Watermark inséré
    plt.subplot(1, 4, 2)
    wm_np = tf.squeeze(watermark).numpy()
    plt.imshow(wm_np[np.newaxis, :], cmap='gray', aspect='auto', vmin=0, vmax=1, interpolation='nearest')

    plt.title("Watermark inséré")
    plt.axis("off")

    # 3. Image tatouée
    plt.subplot(1, 4, 3)
    plt.imshow((tf.squeeze(watermarked).numpy() + 1) / 2)
    plt.title("Image tatouée")
    plt.axis("off")

    # 4. Watermark décodé
    plt.subplot(1, 4, 4)
    decoded_np = tf.squeeze(decoded).numpy()
    plt.imshow(decoded_np[np.newaxis, :], cmap='gray', aspect='auto', vmin=0, vmax=1, interpolation='nearest')

    plt.title("Watermark décodé")
    plt.axis("off")

    if epoch is not None:
        plt.suptitle(f"Affichage - Époque {epoch}", fontsize=14)

    plt.tight_layout()
    plt.show()

watermark_len = 30
image_channels = 3


optimizer_g = tf.keras.optimizers.Adam(learning_rate=1e-4)
optimizer_d = tf.keras.optimizers.Adam(learning_rate=1e-4)
optimizer_dec = tf.keras.optimizers.Adam(learning_rate=5e-4)

!pip install tensorflow-hub tensorflow-probability





from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.models import Model
# On utilise les couches de bas niveau jusqu’à 'block3_conv3'
vgg = VGG16(include_top=False, weights='imagenet', input_shape=(None, None, 3))
vgg.trainable = False  # Gèle les poids

# On crée un sous-modèle VGG
vgg_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)
import tensorflow as tf

def perceptual_loss(y_true, y_pred):
    # Remettre les pixels à l’échelle 0-255 pour VGG16
    y_true = tf.clip_by_value(y_true * 255.0, 0.0, 255.0)
    y_pred = tf.clip_by_value(y_pred * 255.0, 0.0, 255.0)

    # Appliquer le pré-traitement spécifique VGG
    y_true = preprocess_input(y_true)
    y_pred = preprocess_input(y_pred)

    # Extraire les features intermédiaires
    true_features = vgg_model(y_true)
    pred_features = vgg_model(y_pred)

    # Calculer la perte de type MSE sur les features
    return tf.reduce_mean(tf.square(true_features - pred_features))













pip3 install notebook

import os, glob, pickle
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.losses import BinaryCrossentropy



loss_g_list, loss_d_list, accuracy_d_list, bit_accuracy_list, loss_decoded = [], [], [], [], []

# === Fonction de perte binaire
bce = BinaryCrossentropy(from_logits=True)

# === Entraînement principal
for epoch in range(start_epoch, 400):
    loss_g_epoch, loss_d_epoch, acc_d_epoch, bit_acc_epoch, loss_decoded_epoch = [], [], [], [], []

    for images in train_data:
        batch_size = tf.shape(images)[0]
        watermark = tf.cast(tf.random.uniform([batch_size, WATERMARK_LENGTH], minval=0, maxval=2, dtype=tf.int32), tf.float32)

        with tf.GradientTape(persistent=True) as tape:
            watermarked = encoder(images, watermark)
            decoded = decoder(watermarked)

            loss_decode = bce(watermark, decoded)
            loss_img = tf.reduce_mean(tf.square(images - watermarked))
            loss_percep = perceptual_loss(images, watermarked)
            loss_gan = bce(tf.ones_like(discriminator(watermarked)), discriminator(watermarked))

            total_loss_g = 500 * loss_decode + 100 * loss_img + 5 * loss_gan

            real_pred = discriminator(images)
            fake_pred = discriminator(tf.stop_gradient(watermarked))

            loss_d_real = bce(tf.ones_like(real_pred), real_pred)
            loss_d_fake = bce(tf.zeros_like(fake_pred), fake_pred)
            loss_d = loss_d_real + loss_d_fake

        # Appliquer les gradients
        grads_g = tape.gradient(total_loss_g, encoder.trainable_variables + decoder.trainable_variables)
        optimizer_g.apply_gradients(zip(grads_g, encoder.trainable_variables + decoder.trainable_variables))

        grads_d = tape.gradient(loss_d, discriminator.trainable_variables)
        optimizer_d.apply_gradients(zip(grads_d, discriminator.trainable_variables))

        with tf.GradientTape() as tape_dec:
            decoded_train = decoder(watermarked)
            loss_decode_dec = bce(watermark, decoded_train)
        grads_dec = tape_dec.gradient(loss_decode_dec, decoder.trainable_variables)
        optimizer_dec.apply_gradients(zip(grads_dec, decoder.trainable_variables))

        # Évaluation
        acc_real = tf.reduce_mean(tf.cast(real_pred > 0.5, tf.float32))
        acc_fake = tf.reduce_mean(tf.cast(fake_pred < 0.5, tf.float32))
        acc_d = 0.5 * (acc_real + acc_fake)

        predicted_bits = tf.cast(decoded > 0.5, tf.float32)
        bit_accuracy = tf.reduce_mean(tf.cast(predicted_bits == watermark, tf.float32))

        # Stocker métriques
        loss_g_epoch.append(total_loss_g.numpy())
        loss_d_epoch.append(loss_d.numpy())
        acc_d_epoch.append(acc_d.numpy())
        bit_acc_epoch.append(bit_accuracy.numpy())
        loss_decoded_epoch.append(loss_decode.numpy())

    # Moyennes par époque
    loss_g_list.append(np.mean(loss_g_epoch))
    loss_d_list.append(np.mean(loss_d_epoch))
    accuracy_d_list.append(np.mean(acc_d_epoch))
    bit_accuracy_list.append(np.mean(bit_acc_epoch))
    loss_decoded.append(np.mean(loss_decoded_epoch))

    print(f"✅ Epoch {epoch+1}/400")
    print(f"   Discriminator real/fake : {tf.reduce_mean(real_pred):.4f} / {tf.reduce_mean(fake_pred):.4f}")
    print(f"   G loss : {loss_g_list[-1]:.4f} | D loss : {loss_d_list[-1]:.4f}")
    print(f"   Bit accuracy : {bit_accuracy_list[-1]:.4f} | Image loss : {loss_img.numpy():.4f}")


    results = {
        'loss_g': loss_g_list,
        'loss_d': loss_d_list,
        'accuracy_d': accuracy_d_list,
        'bit_accuracy': bit_accuracy_list,
        'loss_decoded': loss_decoded
    }

    # === Affichage exemples
    sample_image = images[0:1]
    sample_wm = watermark[0:1]
    sample_wm_img = watermarked[0:1]
    sample_decoded = decoded[0:1]

    generate_images_from_outputs(sample_image, sample_wm, sample_wm_img, sample_decoded, epoch=epoch+1)



    # Par exemple pour afficher le premier élément du batch
    sample_image = images[0:1]
    sample_wm = watermark[0:1]
    sample_wm_img = watermarked[0:1]
    sample_decoded = decoded[0:1]

    generate_images_from_outputs(sample_image, sample_wm, sample_wm_img, sample_decoded, epoch=epoch+1)
    # Générer et afficher

    # === Tracés intermédiaires ===
    plt.figure(figsize=(12, 8))
    plt.plot(loss_g_list, label='Loss Générateur', color='blue')
    plt.legend(); plt.title("Courbes de pertes ")
    plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.grid(True)
    plt.show()


    plt.figure(figsize=(12, 8))
    plt.plot(loss_d_list, label='Loss Discriminateur', color='red')
    plt.legend(); plt.title("Courbes de pertes ")
    plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.grid(True)
    plt.show()

    plt.figure(figsize=(12, 4))
    plt.plot(accuracy_d_list, label="Précision Discriminateur", color='green')
    plt.title("Précision du Discriminateur"); plt.ylabel("Accuracy"); plt.xlabel("Epoch"); plt.grid(True); plt.legend()
    plt.show()

    # === Sauvegarde des poids



